# Machine learning
Videoâ€¢
. Duration: 6 minutes
6 min

URL: https://www.coursera.org/learn/uol-how-computers-work/lecture/kA0Hg/machine-learning

## VIDEO TRANSCRIPT ## You may navigate through the transcript using tab. To save a note for a section of text press CTRL + S. To expand your selection you may use CTRL + arrow key. You may contract your selection using shift + CTRL + arrow key. For screen readers that are incompatible with using arrow keys for shortcuts, you can replace them with the H J K L keys. Some screen readers may require using CTRL in conjunction with the alt key How do we get a computer to understand images, to recognize faces, or tell the difference between cats and dogs? How can we program a computer to do it, if we don't know how to do it ourselves? The short answer is we can't, but a new approach called Machine Learning is radically changing how we create software to solve these problems. Instead of programming a computer by telling it every detail of how to do a task, we teach it by giving it examples of what to do. If we want a computer to tell the difference between cats and dogs, we can show it lots of pictures of cats and lots of pictures of dogs, and it can learn to tell the difference. But wait, isn't that just magic? Have computers become so intelligent, they can learn just like us? Actually, no, it's all just statistics. Machine learning uses statistical algorithms to learn from examples. We call these examples data, and we say that the computer learns from data. These algorithms are often surprisingly simple, but they can handle a lot of example data. Simple algorithms can perform incredibly well, if they have enough examples. The most popular method at the moment is deep neural networks, often called deep learning. They're cutting edge methods, but they aren't particularly new. Neural networks were invented in the 1940s. The methods used in deep learning are basically the same as those used in the 1980s. So, why have they suddenly started working a lot better? We have a lot more data, as well as the computer power to handle that data. Google's research director and AI pioneer, Peter Norvig, is quoted as saying, "We don't have better algorithms, we just have more data." Let's look in a bit more detail at how machine learning works. Machine learning is about creating statistical programs called Models. A model takes an input and gives you back an output. The input could be a picture, and the output could be the words cat or dog. The model is created based on lots of example data. Each example includes both an input and an output, so it could be a picture of a cat together with the label cat or a picture of a dog with the label dog. A machine learning algorithm takes the examples and uses them to train the model. This means that it adapts the details of the model, so that it maps the inputs in the example data to the corresponding outputs. So, it'd map the top image in the example data to cat and the bottom one to dog. Once the model has been trained, you can give it new input, a picture without a label, and it will tell you the output. The great thing about this, is that it is really generally applicable. The input is just a bunch of numbers, but anything that it's represented on a computer is basically represented as a bunch of numbers. So, the input can be almost anything you can represent to the computer: photographs, speech, music, web pages, bank accounts, social media profiles, DNA sequences, legal decisions, disease symptoms, news stories, astronomical data, or cute kitten videos. Almost anything you do on a computer could have machine learning applied to it, and the basic techniques are pretty much the same. A couple of years ago, I decided that I should learn about natural language processing, the computing techniques for understanding human speech and writing. I thought I'd have to learn a lot of new and difficult techniques, but the first chapter of the book I read was about how to represent words as input to machine learning. The rest of the book was just the same machine learning techniques I'd been using for years in other domains. The outputs can also be lots of different things. In the most common type of machine learning, the output is one of a number of categories called classes, for example, cat, dog or rabbit. Or for medical cases, it could be the name of the disease. Or for face recognition, it could be the name of the person it recognized. There are many, many different tasks they boil down to putting things into categories, so classification is common. All the examples we'll use in this course will be classification, but there are lots of other possible outputs. If the output is a number or several numbers, like how serious diseases is, how emotional some music is, or how cute kitten is, we call it regression. The output can even be new examples. Machine learning can create new images, music, or synthetic speech, in which case we call it a generative model. Whenever we train a model on examples of input and output, we call it supervised learning. But sometimes, we don't know what the right output is. This is very common in science. We might have a lot of DNA sequences and we want to know what different types exist. In this case, we might give the learning algorithm a set of inputs on their own, and get it to figure out the categories, this is called unsupervised learning. A final type of learning works differently. Rather than getting examples, reinforcement learning works much more like training a dog. The algorithm does things and gets rewards for doing good things - like a dog getting a treat - and gets punishments for doing the wrong thing. This is great for playing games. The model gets rewards for winning games and punishment for losing them. AlphaGo, the software that beat the world champion at the game Go, used reinforcement learning to learn which strategies were good based on whether it won or lost games. So, there are many different approaches to machine learning, but all of these different types of learning use statistical algorithms and data. In this course, you'll learn about supervised classification, but many of the basic ideas apply to all types of machine learning. ## END TRANSCRIPT ## ## ADDITIONAL PAGE CONTENT ## Lesson 17.0 Introduction Lesson 17.1 Artificial intelligence Lesson 17.2 Machine learning Video: Video Machine learning . Duration: 6 minutes 6 min Video: Video Machine learning algorithms . Duration: 6 minutes 6 min Reading: Reading Machine learning exercise . Duration: 15 minutes 15 min Ungraded Plugin: Machine learning . Duration: 15 minutes 15 min Discussion Prompt: How did you find machine learning? . Duration: 30 minutes 30 min Video: Video Interview with Machine Learning experts . Duration: 7 minutes 7 min
# Machine learning algorithms
Videoâ€¢
. Duration: 6 minutes
6 min

URL: https://www.coursera.org/learn/uol-how-computers-work/lecture/VQdJA/machine-learning-algorithms

## VIDEO TRANSCRIPT ## You may navigate through the transcript using tab. To save a note for a section of text press CTRL + S. To expand your selection you may use CTRL + arrow key. You may contract your selection using shift + CTRL + arrow key. For screen readers that are incompatible with using arrow keys for shortcuts, you can replace them with the H J K L keys. Some screen readers may require using CTRL in conjunction with the alt key How does machine learning actually work? It can sound a bit like magic. You give the computer some examples and it magically learns how to do the right thing. But, it isn't magic. Machine learning is based on algorithms, that are normally quite stupid but can do some incredible things if you give them enough data. Most machine learning algorithms are based on statistics, and could be quite mathematical and complex. Part of the philosophy of this course is that you don't need to understand all the details of the algorithm to do machine learning. But in this lecture, I'd like to give you a sense of how some algorithms work so that it doesn't seem too mysterious to you. For example, you have lots of pictures of cats and lots of pictures of dogs. You're given a new picture and have to decide if it's a cat or a dog. How can you do it? One simple way of doing this is to look through all the original examples and find the one that's most similar to the new picture, and use its class. It's a very simple method but can actually work quite well. In fact, it's an established algorithm with its own name, nearest neighbor. It's called that because you're classifying a picture based on the nearest example, which we call its neighbor. It works as an algorithm, but it can be improved. For example, there are times when a dog picture might look a lot like a cat picture. In that case, the nearest neighbor will be wrong. We can never completely eliminate errors like that. But one way we can reduce them, is to use more than one neighbor. We could use the three closest examples and choose the class that most of them have. We normally name the number of neighbours with the letter K, and call the algorithm K nearest neighbours or kNN. One nearest neighbor is hardly ever used but K nearest neighbours is actually a very commonly used machine learning algorithm. Another issue with nearest neighbor, is what we mean by near or similar. The algorithm needs a mathematical definition of similarity that will give a number writing how similar two items are. For example, for pictures, you might measure how different each pixel is and add up all the results to get the score. But as we'll see in future videos, using individual pixels often doesn't work well. A lot of the work of using nearest neighbours is about having a good measure of similarity, which in turn, normally means having a good representation of pictures or whatever we are trying to classify. This is something we'll look at in the video on data features. In fact, the machine-learning software you will use in this course is based on K nearest neighbours together with a really sophisticated measure of similarity. Another problem with nearest neighbours is that it can be slow. You have to search through every single example to find the most similar. One solution is to select only a small number of important examples to compare with, and throw the rest away. Comparing with a small number of important examples, together with a very sophisticated similarity measure, and a bunch of other clever stuff, is the basis of a method called Support Vector Machines, which is state of the art when I started machine learning and is still very important. Another approach is to not use the original examples directly, but to use them to create a mathematical function to do the classification. This function is called a model. Let's look at a simple example. Dogs are bigger than cats, so we can try to classify based on size. Assuming we can calculate size from an image which is admittedly pretty hard, we could classify all animals above a certain size as dogs and below that size as cats. This is a very simple mathematical function that can do classification. Comparing size with a certain value that we call the threshold. How do we know what to use as a threshold? We can do it based on the data. We choose the value that gives us the smallest number of incorrect classifications. This is an example of a process called optimization. Optimization means choosing the numbers that we use in our models so that they give us the best results on the training data. In this case, we're choosing the threshold, the size above which we classify animals as dogs. Most machine learning algorithms use some form of optimization. Classifying cats and dogs by only on size won't work very well. It'll do okay for most dogs but fail for tiny Chihuahuas, little puppies and fat cats. But we can do a lot better if we combine together other features. For example, we could use ear shape and nose length. One method called Decision Trees combines many simple decisions on individual features. The algorithm performs one decision after another, choosing features to use based on the previous decision. It might first make a decision based on size, and then split up the small animals based on ear shape. The features to use, the order in which they're used, and the threshold values are all learned from data using optimization. Other algorithms like neural networks combine many features together into complex mathematical functions and only make one decision based on the output of that function. The details of the function are also learned from data using optimization. So, most machine learning algorithms are based on combining together many features of the data into mathematical functions called models. The details of these models are chosen automatically, so they give the best results on the training data, a process called Optimization. The details of the algorithms vary a lot, but having this basic understanding of how they work in general, will give you a good foundation for understanding how to do machine learning. ## END TRANSCRIPT ## ## ADDITIONAL PAGE CONTENT ## Lesson 17.0 Introduction Lesson 17.1 Artificial intelligence Lesson 17.2 Machine learning Video: Video Machine learning . Duration: 6 minutes 6 min Video: Video Machine learning algorithms . Duration: 6 minutes 6 min Reading: Reading Machine learning exercise . Duration: 15 minutes 15 min Ungraded Plugin: Machine learning . Duration: 15 minutes 15 min Discussion Prompt: How did you find machine learning? . Duration: 30 minutes 30 min Video: Video Interview with Machine Learning experts . Duration: 7 minutes 7 min
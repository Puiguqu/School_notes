# Problems with machine learning: overfitting
Videoâ€¢
. Duration: 3 minutes
3 min

URL: https://www.coursera.org/learn/uol-how-computers-work/lecture/IMCwl/problems-with-machine-learning-overfitting

## VIDEO TRANSCRIPT ## You may navigate through the transcript using tab. To save a note for a section of text press CTRL + S. To expand your selection you may use CTRL + arrow key. You may contract your selection using shift + CTRL + arrow key. For screen readers that are incompatible with using arrow keys for shortcuts, you can replace them with the H J K L keys. Some screen readers may require using CTRL in conjunction with the alt key Did all of the data sets work? If not, why did some of them fail? There are lots of reasons why certain data sets do not work well for machine learning. The basic reason is that the machine learning algorithm is actually doing its job. It's learning what's in the training data set. But that isn't always what we wanted to learn, and it doesn't always transfer over to the testing set or the real world. This is often because it learns aspects of the training set that are irrelevant to the task. There was a classic example of a system that was trying to recognize tanks, and did very well on the training set but completely failed in the real world. The developers realized that they had taken all of the pictures of the tanks on a cloudy day. The system learned the lighting conditions not the tanks themselves. There was some technical solutions to this type of problem. Very complex models can learn every little detail of the training set. Therefore, lots of irrelevant details. That's why most machine learning practitioners favor using models that are as simple as possible while still being able to do the job. When it comes to doing machine learning though, often the best thing you can do is make sure you have a good data set. When collecting a data set, you have to check whether there's anything about how you are collecting the data that would not be true of the real world. Are all the pictures against the same background? In the same lighting conditions? Is the person you're trying to recognize always wearing a hat or glasses? Do they have their hair tied back? Are they always wearing the same makeup? The more you can vary any of these things in your data set the better. Try to capture images and as many conditions as possible. Make sure that your training and test sets are as representative as possible of the data you will be getting in the real world, so that your model isn't surprised by a very different type of image. In short, do everything you can to make sure your algorithm is learning what you want it to learn and can't cheat by using irrelevant features to make decisions. What if once you've tested your model it doesn't work as you'd expected? This is when you should really start looking at the examples that aren't classified correctly. Can you see any patterns in the mistakes the model is making? Maybe you haven't got enough training examples that are similar to a particular example in your testing set. Maybe certain items in one class looks similar to training examples in another class. Most of the time, you can fix problems by adding new training examples that show the learning algorithm the difference between two classes. For example, if you don't have any gray dogs in your training set and lots of gray cats, It might think that this is a cat. It should be quite easy to fix the problem. Go and find some pictures of gray dogs. Sometimes, two classes might just be too hard to tell apart, and you might need to rethink the problem a bit. Maybe limiting the set of classes or making sure your images are taken under more controlled conditions, which is fine as long as your real-world examples that you'll use later will also be in control conditions. Getting a working machine learning model is not an exact science. Even the world's greatest experts spend a lot of time trying to improve their models through trial and error. The important thing is to spend a lot of time testing the model, and when it goes wrong, look carefully at the data that's misclassified and do your best to improve the training set. ## END TRANSCRIPT ## ## ADDITIONAL PAGE CONTENT ## Lesson 19.0 Introduction Lesson 19.1 Testing Video: Video Testing . Duration: 2 minutes 2 min Reading: Reading Trying different datasets . Duration: 15 minutes 15 min Ungraded Plugin: Trying different datasets . Duration: 2 hours 2h Reading: Reading Evaluating the four datasets . Duration: 15 minutes 15 min Discussion Prompt: How does machine learning go wrong? . Duration: 30 minutes 30 min Video: Video Problems with machine learning: overfitting . Duration: 3 minutes 3 min Lesson 19.2 Societal Impact of Machine Learning
# Dangers of machine learning
Videoâ€¢
. Duration: 8 minutes
8 min

URL: https://www.coursera.org/learn/uol-how-computers-work/lecture/iJUPK/dangers-of-machine-learning

## VIDEO TRANSCRIPT ## You may navigate through the transcript using tab. To save a note for a section of text press CTRL + S. To expand your selection you may use CTRL + arrow key. You may contract your selection using shift + CTRL + arrow key. For screen readers that are incompatible with using arrow keys for shortcuts, you can replace them with the H J K L keys. Some screen readers may require using CTRL in conjunction with the alt key Although machine learning is an exciting technology that has a lot of potential to make our lives better, we should also look at the potential dangers. A lot of people worry about the potential for artificial intelligence to be too successful. The computers will become more intelligent than humans and will take over the world. This view is well-expressed by Nick Bostrom in his book Superintelligence. many thinkers in this area, he thinks there's a potential for an intelligence explosion in which an AI that is more intelligent than humans will event a more intelligent AI, which in turn will invent an even more intelligent AI, and so on until we have a vastly superintelligent computer that will take over the world, all possibly in a matter of minutes. I personally think that although superhuman artificial intelligence is possible eventually, this scenario is unlikely. Having worked in many areas relates to AI for many years, I realized that it's very hard. Creating human-level intelligence and beyond will take a lot of work, and there's many conceptual breakthroughs. Simply having more memory or processing power, which is what an AI is likely to bring, will not mean that these problems can be solved instantly. But that doesn't mean we shouldn't worry about machine learning technology. Pedro Domingo, machine learning professor and author of The Master Algorithm, one of the best books on machine learning for general public, puts it nicely. People worry that computers will get too smart and take over the world, but the real problem is that they're too stupid and they've already taken over the world. Machine learning is now being used in lots of very important roles, and we should worry about the possible negative implications. Even if we are mostly worried about superintelligence, I think that the best way of dealing with its dangers is to deal with the dangers of the AI we currently have. That way, our defenses against the dangers of AI will evolve together with the AI itself, and we'll be more prepared if and when it does become superintelligence. One of the most obvious effects of machine learning and AI is on jobs. If machine learning systems can do things that previously only humans could do, there's a risk that our jobs will be taken over by machines. There is already evidence that this is happening, as described by Martin Ford in his book Rise of The Robots. This can affect any kind of job, from taxi drivers being replaced by self-driving cars to doctors and lawyers being replaced by automatic diagnosis or legal case search. How we deal with this situation is more of a political challenge than a technological one. We could end up in a situation of mass unemployment and poverty, but we could also end up in a science fiction utopia in which we all have to work much less and benefit from all the work done for us by the machines. Whichever happens is down to the choices we make about how we want our society to work, and those are very much political choices. Job automation is about machine learning working well, but there are lots of problems due to machine learning not working as we want. A big issue is biased in machine learning models. We tend to think of computers as objective and unbiased, but researchers like Kate Crawford have shown that machine learning models can show the same sort of bias that humans have. For example, machine learning systems used by banks can disproportionately refuse loans to certain ethnic groups. This is often called algorithmic bias, but the bias is not really in the algorithms. Machine learning algorithms do have one major bias. They aim to reproduce what they see in the data. That isn't really a bias. It's what the algorithm is supposed to do. The trouble is that a lot of data for the real world is biased because the real world itself has bias. A machine-learning algorithm might associate the word surgeon with men, but nurse with women. This might accurately reflect current data because a lot of texts out there include male surgeons and female nurses. But that doesn't mean that's what we want the system to learn. There are increasing number of female surgeons and male nurses, and we want more women in medicine. The same goes for police work. If in a certain country there's an ethnic or religious bias in police arrests, this will be reflected in the data. But we want to eliminate bias, not reinforce it. This means we have to be very careful about the datasets we use. I've said before that it's important that our datasets are representative. But this is even more important if the data is unrepresentative in a way that perpetuates existing social biases. It's harder than it seems. For me working in London, it's very easy to gather data that's fairly representative of the UK. But if I want a machine learning system for use globally, my data might be very unrepresentative of other countries. One really important aspect of data that we've already learned about is features. It's not only important which examples of data we use, but the features we include about in each example. One way of trying to eliminate bias is to ignore features such as race or gender. That sounds like a good idea. A machine learning algorithm can't actually be biased by race if it doesn't know people's race. Unfortunately, it isn't that simple because other seemingly innocuous data features might be associated with race or gender. For example, clothes shopping habits can reveal gender. Postcards might reveal race if people from certain ethnic groups tend to live in different parts of a city. Once you start thinking about it, you realize there aren't many features that don't show bias in some way. Biased systems can be particularly dangerous if they are making important decisions about us. I've mentioned machine learning systems being used to inform police work. But there are many others. Machine learning systems now influence whether we get insurance, a bank loan, or even a job. Machine learning systems are being used in certain US school districts to decide which school teachers are underperforming and which should be fired. Cathy O'Neil has a phase for these types of potentially biased machine learning systems in life-changing roles, "Weapons of math destruction." The dangers are enhanced by the fact that many machine learning methods like neural networks are very complex and hard to interpret. This means it's very hard to know why a model has made a certain decision. If we don't know why a decision was made, there's no way to appeal against it or to make the system work better. If people trust the model without checking how it works, because they can't, we end up with important decisions being made about people that no one understands and that no one can know whether they were right or wrong. So, it's really important that we think carefully about the future of machine learning. It's a very powerful technology, but we have to make sure we use it in the right way. That's where you come in. If machine learning takes over human jobs, we have to work out what we can do instead, and that is a conversation you can be part of. I think one very important job in the future will be teaching the machine learning models that do the work. That's why learning about machine learning is very important. It might be a key skill you need for your next job. You're now more ready to be involved in the conversation about the future of work. Making sure that machine learning models are not biased means making sure that data is representative. I believe that one of the best ways of doing this is making sure that the people who do machine learning are as representative as possible. If only a few people are involved in machine learning, they will inevitably bring that biases to the system, whether they mean to or not. The more different kinds of people are involved in collecting datasets and training models, the likely they are to find and correct biases. This is part of the reason I'm teaching this course, because I want all of you to be part of machine learning. Each and every one of you will have a different background and perspective, which means that you will bring a different point of view to machine learning. Each and every one of you has an important contribution to make to machine learning, and I want you all to make that contribution. Let's all work together to make sure that machine learning makes this world a better place, not a worse one. ## END TRANSCRIPT ## ## ADDITIONAL PAGE CONTENT ## Lesson 19.0 Introduction Lesson 19.1 Testing Lesson 19.2 Societal Impact of Machine Learning Video: Video Applications of machine learning . Duration: 3 minutes 3 min Discussion Prompt: Applications of machine learning . Duration: 30 minutes 30 min Video: Video Dangers of machine learning . Duration: 8 minutes 8 min Discussion Prompt: Dangers of machine learning . Duration: 30 minutes 30 min Video: Video Interview: Benefits and danger of Machine Learning . Duration: 18 minutes 18 min
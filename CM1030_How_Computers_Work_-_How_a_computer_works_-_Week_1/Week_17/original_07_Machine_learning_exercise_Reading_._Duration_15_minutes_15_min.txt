# Machine learning exercise
Readingâ€¢
. Duration: 15 minutes
15 min

URL: https://www.coursera.org/learn/uol-how-computers-work/supplement/jZsig/machine-learning-exercise

In the next exercise you will use an interactive plugin to get your first experience of doing machine learning. NB: The video input on this plugin does not work on all browsers. Recent tests have tended to show it working in browsers that are NOT-based on the Chromium engine (e.g. Chrome, Brave etc.). We would therefore you suggest trying this with Firefox if you haven't already. If you continue to have problems in the browser, then you can use the plugin here on github: https://andyfication.github.io/ The plugin looks like this: At the top is a live video from your web cam. Make sure you select video so that you can see the video. The machine learning algorithm will learn and classify your video (if you do not have a camera on your computer you can select "From File" to load images instead, but for this exercise it will be easier to use the camera if you have one). In this exercise you will use the plugin to classify images. That means you need to have two or three classes of things that you are going to show to the camera and you will expect it to recognise. In this case I will teach the algorithm to tell the difference between me being in the video and me not being there (the blank background). I start by naming my first class, by typing into the text box shown below. I then sit in front of the camera and adding these videos to the "me" class. I use the "Add to Class" button to do that. Each time I do that it adds the current picture as a training example. You can see the training examples in little thumbnail images next to the "Add to Class" button. I can then add some images of the background to class 2: Now I can test it. I select classify, and it switches from training mode to classification mode: It will then run the current video image through the classifier you have just trained and it will predict what class it thinks the image belongs to. As you can see below, with an image of me in the frame, it is predicting "Me" so it is working! I can also test it on an image without me in the frame, and it correctly predicts it as "Background". Now you can have a go. Try to train three different classes and see if the machine learning algorithm can tell the difference. Lesson 17.0 Introduction Lesson 17.1 Artificial intelligence Lesson 17.2 Machine learning Video: Video Machine learning . Duration: 6 minutes 6 min Video: Video Machine learning algorithms . Duration: 6 minutes 6 min Reading: Reading Machine learning exercise . Duration: 15 minutes 15 min Ungraded Plugin: Machine learning . Duration: 15 minutes 15 min Discussion Prompt: How did you find machine learning? . Duration: 30 minutes 30 min Video: Video Interview with Machine Learning experts . Duration: 7 minutes 7 min Machine learning exercise In the next exercise you will use an interactive plugin to get your first experience of doing machine learning. NB: The video input on this plugin does not work on all browsers. Recent tests have tended to show it working in browsers that are NOT-based on the Chromium engine (e.g. Chrome, Brave etc.). We would therefore you suggest trying this with Firefox if you haven't already. If you continue to have problems in the browser, then you can use the plugin here on github: https://andyfication.github.io/ The plugin looks like this: At the top is a live video from your web cam. Make sure you select video so that you can see the video. The machine learning algorithm will learn and classify your video (if you do not have a camera on your computer you can select "From File" to load images instead, but for this exercise it will be easier to use the camera if you have one). In this exercise you will use the plugin to classify images. That means you need to have two or three classes of things that you are going to show to the camera and you will expect it to recognise. In this case I will teach the algorithm to tell the difference between me being in the video and me not being there (the blank background). I start by naming my first class, by typing into the text box shown below. I then sit in front of the camera and adding these videos to the "me" class. I use the "Add to Class" button to do that. Each time I do that it adds the current picture as a training example. You can see the training examples in little thumbnail images next to the "Add to Class" button. I can then add some images of the background to class 2: Now I can test it. I select classify, and it switches from training mode to classification mode: It will then run the current video image through the classifier you have just trained and it will predict what class it thinks the image belongs to. As you can see below, with an image of me in the frame, it is predicting "Me" so it is working! I can also test it on an image without me in the frame, and it correctly predicts it as "Background". Now you can have a go. Try to train three different classes and see if the machine learning algorithm can tell the difference. Mark as completed Dislike Report an issue
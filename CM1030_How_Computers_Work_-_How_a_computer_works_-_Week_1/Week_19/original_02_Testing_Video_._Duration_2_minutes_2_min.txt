# Testing
Videoâ€¢
. Duration: 2 minutes
2 min

URL: https://www.coursera.org/learn/uol-how-computers-work/lecture/S3e1e/testing

## VIDEO TRANSCRIPT ## You may navigate through the transcript using tab. To save a note for a section of text press CTRL + S. To expand your selection you may use CTRL + arrow key. You may contract your selection using shift + CTRL + arrow key. For screen readers that are incompatible with using arrow keys for shortcuts, you can replace them with the H J K L keys. Some screen readers may require using CTRL in conjunction with the alt key How do we know if machine learning has worked? You've probably already discovered the results are often not what you expect or want. In fact, even when a machine learning model works well, it's almost never completely perfect. It will still make mistakes on occasion. Often we humans can't do tasks like recognizing faces perfectly, so how could we expect computers to do so? But that makes it quite hard to work out if a system is working acceptably, because you'll never get it to be 100% correct. A good start is to see how much of the data it classifies correctly. Once your algorithm is finished learning, you can test it by classifying each item in the training data and see what percentage it gets right. But it can be hard to determine good results. It can depend on your application. Classifying cat images correctly 99% of the time is really good but a self-driving car that fails to see pedestrians even 1% of the time could be fatal. Sometimes it's worth looking at how well humans do on a task. If people can only classify an emotion in the face correctly 70% of the time, you probably can't expect machine learning to do much better. You might also want to favor certain types of error. In a medical test it's probably better to be cautious and erroneously recognize a disease in a healthy patient than fail to spot it in an ill patient. Classifying the training set well is good, but you really want your model to do well on new data. Machine learning works by optimizing the model so that it performs well on the training data. That means it can learn all the details in the training data and do very well on it. But it probably won't do as well on new data that was not in the training set. This is why machine learning practitioners keep some data just for testing. This test data is not used during the training phase so, it's fair test using the training data. The percentage of correct classifications on the test set will give a much better idea of how well your model will work in practice. You should typically split your data into a training set and a test set. The training set should be bigger so that you have enough data for your algorithm to learn effectively. A good split might be four-fifths training and one-fifth testing. Testing is a really important part of machine learning. Professionals often use complex testing methods, with multiple data sets. But splitting your data into train and test sets is a really good start. ## END TRANSCRIPT ## ## ADDITIONAL PAGE CONTENT ## Lesson 19.0 Introduction Lesson 19.1 Testing Video: Video Testing . Duration: 2 minutes 2 min Reading: Reading Trying different datasets . Duration: 15 minutes 15 min Ungraded Plugin: Trying different datasets . Duration: 2 hours 2h Reading: Reading Evaluating the four datasets . Duration: 15 minutes 15 min Discussion Prompt: How does machine learning go wrong? . Duration: 30 minutes 30 min Video: Video Problems with machine learning: overfitting . Duration: 3 minutes 3 min Lesson 19.2 Societal Impact of Machine Learning
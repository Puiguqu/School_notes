# Asymptotic complexity Videoâ€¢ . Duration: 6 minutes 6 min

[Original lesson](https://www.coursera.org/learn/uol-fundamentals-of-computer-science/lecture/zRERE/asymptotic-complexity)

Here is a summary of the text in 8 sentences, preserving key information and technical details:

The video transcript discusses the asymptotic complexity of algorithms, which refers to the time required by an algorithm as a function of input size (n). The efficiency of an algorithm can be compared by looking at its graph, where the shape represents the growth rate. To determine the asymptotic behavior, one must consider the fastest-growing term in the function and strip it from its coefficient. There are five main cases: constant functions (like 2n^2 + 5), linear functions (like n log n), quadratic functions (like 3n^2 + 4n), cubic functions (higher-order polynomials), and exponential functions. Each case has a specific order of asymptotic behavior, with logarithmic functions growing slower than constant functions, which in turn grow slower than linear functions, and so on. The video provides examples to illustrate each case, including the best-case and worst-case scenarios for sorting algorithms like insertion sort. The goal of asymptotic analysis is to estimate how slow an algorithm becomes as input size increases. By identifying the fastest-growing term in a function, one can determine the class of function it belongs to and predict its growth rate.

Note: I removed some technical details and formulas not explicitly mentioned in the original text, but preserved key concepts and ideas.


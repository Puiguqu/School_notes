# Asymptotic complexity Videoâ€¢ . Duration: 6 minutes 6 min

[Original lesson](https://www.coursera.org/learn/uol-fundamentals-of-computer-science/lecture/zRERE/asymptotic-complexity)

Here is a summary of the text in 8 sentences, preserving key information and concepts:

The asymptotic complexity of algorithms refers to the time required by an algorithm as a function of the size of the input (n). This can be represented graphically, allowing for comparison of efficiency between different algorithms. Asymptotic behavior measures how fast an algorithm's running time grows as n increases, ignoring small terms in the function. To determine asymptotic behavior, one must identify the fastest-growing term in the function and strip it of its coefficient. The order of asymptotic behavior is: constant functions (e.g., f(n) = 6), logarithmic functions (e.g., g(n) = log(n)), linear functions (e.g., h(n) = 4n + 5), quadratic functions (e.g., i(n) = 2n^2 - 3n), and exponential functions. Algorithms with higher order polynomial functions, such as cubic or higher-order polynomials, are also included in this classification. The asymptotic function determines the shape of the graph representing the algorithm's efficiency, allowing for comparison and analysis of an algorithm's performance. Understanding asymptotic behavior is crucial for analyzing and optimizing algorithms, ensuring they scale efficiently with increasing input sizes.


# Worst-case complexity of binary search Videoâ€¢ . Duration: 5 minutes 5 min

[Original lesson](https://www.coursera.org/learn/uol-algorithms-and-data-structures-1/lecture/qerOE/worst-case-complexity-of-binary-search)

Here is a summary of the text in 8 sentences, preserving key information and technical details:

The worst-case time complexity of linear search was found to be O(n), while binary search has been computed to have a worst-case time complexity of O(log n). The best-case input for binary search occurs when the value being searched for is at the midpoint of the vector, resulting in a time complexity of O(1) or constant. In contrast, the first element of the vector in linear search results in the best case scenario due to early inspection. Worst-case inputs for binary search include scenarios where the value is stored in the first element of the vector or next to the midpoint, requiring multiple divisions by two until reaching a single-element vector. The key observation here is that each step of inspecting the midpoint and not finding the value results in halving the vector, which translates to O(log n) inspections in total. This principle also applies when considering scenarios with n slices of pizza being divided among friends, illustrating the exponential reduction in operations. Binary search has a significant advantage over linear search for sorted arrays, with a worst-case time complexity that is exponentially smaller (O(log n) vs O(n)). However, using binary search on unsorted arrays may not be effective without sorting first, as the sorting algorithm's time complexity can dominate the overall process, making linear search more suitable in such cases.

